#include <HPCortex.hpp>
#include <Testing.hpp>

/**
 * @brief Tests the basic functionality of tensors.
 *
 * This function tests various aspects of tensor operations, including 
 * tensor size calculation, offset mapping, and data access.
 
void testTensor() 
 * @brief Calculates the total number of elements in a tensor with the given dimensions.
 *
 * @tparam Dim The number of dimensions in the tensor.
 * @param dims An array containing the size of each dimension.
 * @return The total number of elements in the tensor.
 
template <size_t Dim>
size_t tensorSize(const int dims[Dim])
 * @brief Maps a coordinate to its corresponding linear index in a tensor.
 *
 * @tparam Dim The number of dimensions in the tensor.
 * @param coord An array containing the coordinates of the element.
 * @param dims An array containing the size of each dimension.
 * @return The linear index of the element in the tensor.
 
template <size_t Dim>
size_t tensorOffset(const int coord[Dim], const int dims[Dim])
 * @brief Unmaps a linear index to its corresponding coordinates in a tensor.
 *
 * @tparam Dim The number of dimensions in the tensor.
 * @param coord An array to store the coordinates of the element.
 * @param dims An array containing the size of each dimension.
 * @param offset The linear index of the element in the tensor.
 
template <size_t Dim>
void tensorOffsetUnmap(int coord[Dim], const int dims[Dim], size_t offset)
 * @class Tensor
 * @brief A class representing a multi-dimensional tensor.
 *
 * @tparam FloatType The type of floating-point numbers used in the tensor.
 * @tparam Dim The number of dimensions in the tensor.
 
template <typename FloatType, size_t Dim>
class Tensor 
 * @brief Constructs a tensor with the given dimensions and initial values.
 *
 * @param dims An array containing the size of each dimension.
 * @param init The initial values of the tensor elements.
 
Tensor(const int dims[Dim], const std::vector<FloatType>& init)
 * @brief Returns the size of the specified dimension.
 *
 * @param d The dimension index.
 * @return The size of the specified dimension.
 
size_t size(size_t d) const
 * @brief Accesses the tensor data on the host side.
 *
 * @param func A lambda function to be executed on the host side.
 
void doHost(const std::function<void()> func) const
 * @brief Peeks at the last dimension of the tensor at the specified index.
 *
 * @param index The index of the last dimension to peek at.
 * @return A new tensor representing the peeked data.
 
Tensor<FloatType, Dim-1> peekLastDimension(size_t index) const
 * @brief Pokes the last dimension of the tensor with the given data at the specified index.
 *
 * @param data The data to poke into the tensor.
 * @param index The index of the last dimension to poke at.
 
void pokeLastDimension(const Tensor<FloatType, Dim-1>& data, size_t index)
 * @brief Checks if two tensors are equal.
 *
 * @param other The other tensor to compare with.
 * @return True if the two tensors are equal, false otherwise.
 
bool equal(const Tensor& other) const
 * @brief Fills the tensor with random values.
 *
 * @param rng A random number generator.
 
void random(std::mt19937& rng)
 * @brief Asserts that two floating-point numbers are nearly equal within a certain tolerance.
 *
 * @param a The first floating-point number.
 * @param b The second floating-point number.
 * @param tol The tolerance for near equality.
 
void assertNear(FloatType a, FloatType b, FloatType tol)* This comment was generated by meta-llama/Llama-3.3-70B-Instruct:None at temperature 0.2.
*/ 
void testTensor(){
  typedef double FloatType; 
  typedef std::vector<FloatType> vecD;
  std::mt19937 rng(1234);
  //Test some basic functionality
  {
    int dims[3] = {2,3,4};
    size_t size = 2*3*4;
    assert( tensorSize<3>(dims) == size );
            
    vecD input(size);
    vecD expect(size);
    for(int i=0;i<2;i++)
      for(int j=0;j<3;j++)
	for(int k=0;k<4;k++){
	  size_t off = k + 4*(j + 3*i);
	  int coord[3] = {i,j,k};
	  
	  assert(tensorOffset<3>(coord,dims) == off);

	  int test_coord[3];
	  tensorOffsetUnmap<3>(test_coord,dims,off);
	  for(int ii=0;ii<3;ii++) assert(test_coord[i] == coord[i]);	  
	  
	  input[off] = 3.141 * off;

	  expect[off] = input[off] + 0.15*off*off;
	}
    
    //Try a host-side kernel
    Tensor<FloatType,3> tens_host(dims, input);
    for(int d=0;d<3;d++)
      assert(tens_host.size(d) == dims[d]);
    
    {
      autoView(tens_host_v,tens_host,HostReadWrite);
    
      thread_for3d(i,2,j,3,k,4,{
	  int coord[3] = {(int)i,(int)j,(int)k};
	  size_t off = tensorOffset<3>(coord,dims);
	  tens_host_v(coord) = tens_host_v(coord) + 0.15 * off * off;
	});
    }
    {  
      autoView(tens_host_v,tens_host,HostRead);
      for(int i=0;i<2;i++)
	for(int j=0;j<3;j++)
	  for(int k=0;k<4;k++){
	    size_t off = k + 4*(j + 3*i);
	    int coord[3] = {(int)i,(int)j,(int)k};
	    assert(abs_near(tens_host_v(coord), expect[off],1e-8 ));
	  }
    }

    //Try a device-side kernel
    Tensor<FloatType,3> tens_device(dims, input);
    {
      autoView(tens_device_v,tens_device,DeviceReadWrite);
    
      accelerator_for3d(i,2,j,3,k,4,  1,{
	  int coord[3] = {(int)i,(int)j,(int)k};
	  size_t off = tensorOffset<3>(coord,dims);
	  tens_device_v(coord) = tens_device_v(coord) + 0.15 * off * off;
	});
    }
    {  
      autoView(tens_device_v,tens_device,HostRead);
      for(int i=0;i<2;i++)
	for(int j=0;j<3;j++)
	  for(int k=0;k<4;k++){
	    size_t off = k + 4*(j + 3*i);
	    int coord[3] = {(int)i,(int)j,(int)k};
	    assert(abs_near(tens_device_v(coord), expect[off], 1e-8) );
	  }
    }    
    
  }

  //Test fixed dim accessors
  {
    {
      vecD init({1.1,2.2,3.3});
      int sz = 3;
      Tensor<FloatType,1> tens_1(&sz, init);      
      doHost(tens_1, { assert(tens_1_v(0) == 1.1 && tens_1_v(1) == 2.2 && tens_1_v(2) == 3.3); });
    }
    {
      vecD init({
	  1.1,2.2,3.3,
	  4.4,5.5,6.6
	});
      int sz[2] = {2,3};
      Tensor<FloatType,2> tens_2(sz, init);
      doHost(tens_2, {
	  for(int i=0;i<2;i++)
	    for(int j=0;j<3;j++)
	      assert(tens_2_v(i,j) == init[j+3*i]);
	});
    }

    {
      int sz[3] = {2,3,4};
      vecD init(2*3*4);
      for(int i=0;i<2;i++)
	for(int j=0;j<3;j++)
	  for(int k=0;k<4;k++)
	    init[k+4*(j+3*i)] = (k+4*(j+3*i))*1.1;

      Tensor<FloatType,3> tens_3(sz, init);
      doHost(tens_3, {
	  for(int i=0;i<2;i++)
	    for(int j=0;j<3;j++)
	      for(int k=0;k<4;k++)
		assert(tens_3_v(i,j,k) == init[k+4*(j+3*i)]);
	});
    }

    {
      int sz[4] = {2,3,4,5};
      vecD init(2*3*4*5);
      for(int i=0;i<2;i++)
	for(int j=0;j<3;j++)
	  for(int k=0;k<4;k++)
	    for(int l=0;l>5;l++)
	      init[l+5*(k+4*(j+3*i))] = (l+5*(k+4*(j+3*i)))*1.1;

      Tensor<FloatType,4> tens_4(sz, init);
      doHost(tens_4, {
	  for(int i=0;i<2;i++)
	    for(int j=0;j<3;j++)
	      for(int k=0;k<4;k++)
		for(int l=0;l<5;l++)
		  assert(tens_4_v(i,j,k,l) == init[l+5*(k+4*(j+3*i))]);
	});
    }

    { //test peek/pokeLastDimension
      int sz[3] = {2,3,4};
      Tensor<FloatType,3> orig(sz);
      random(orig,rng);

      int szp[2] = {2,3};
      Tensor<FloatType,2> topoke(szp);
      Tensor<FloatType,2> topoke2(szp);
      random(topoke,rng);
      random(topoke2,rng);

      Tensor<FloatType,3> result(orig);
      result.pokeLastDimension(topoke,0);
      doHost2(result, topoke, {
	  for(int i=0;i<2;i++)
	    for(int j=0;j<3;j++)
		assert(result_v(i,j,0) == topoke_v(i,j));
	});
      result.pokeLastDimension(topoke2,2);
      
      doHost3(result, topoke, topoke2, {
	  for(int i=0;i<2;i++)
	    for(int j=0;j<3;j++){
		assert(result_v(i,j,0) == topoke_v(i,j));
		assert(result_v(i,j,2) == topoke2_v(i,j));
	      }		
	});

      Tensor<FloatType,2> r0 = result.peekLastDimension(0);
      Tensor<FloatType,2> r2 = result.peekLastDimension(2);
      assert(equal(r0,topoke));
      assert(equal(r2,topoke2));
    }

  }

  
  std::cout << "testTensor passed" << std::endl;
}


/**
 * @brief Tests iteration over dimensions of tensors with varying sizes.
 *
 * This function creates tensors of different sizes and checks that iterating
 * over their dimensions produces the expected results.
 
void testDimensionIteration()* This comment was generated by meta-llama/Llama-3.3-70B-Instruct:None at temperature 0.2.
*/ 
void testDimensionIteration(){
  typedef double FloatType;
  std::mt19937 rng(1234);
  {
    int size[2] = {3,4};
    Tensor<FloatType,2> tens(size);
    random(tens,rng);

    size_t stride0 = tensorDimensionStride<2>(0,size);
    size_t stride1 = tensorDimensionStride<2>(1,size);
        
    doHost(tens, {
	//iter_dim=0
	for(int d1=0;d1<4;d1++){
	  size_t base = tensorDimensionBase<2>(0, &d1, size);
	  for(int d0=0;d0<3;d0++)      
	    assert( tens_v.data()[base + d0*stride0] == tens_v(d0,d1) );
	}

	//iter_dim=1
	for(int d0=0;d0<3;d0++){
	  size_t base = tensorDimensionBase<2>(1, &d0, size);
	  for(int d1=0;d1<4;d1++)      
	    assert( tens_v.data()[base + d1*stride1] == tens_v(d0,d1) );
	}
      });
  }

  {
    int size[3] = {3,4,5};
    Tensor<FloatType,3> tens(size);
    random(tens,rng);
    
    size_t stride0 = tensorDimensionStride<3>(0,size);
    size_t stride1 = tensorDimensionStride<3>(1,size);
    size_t stride2 = tensorDimensionStride<3>(2,size);

    doHost(tens, {
	//iter_dim=0
	int other_coord[2];
	for(int d1=0;d1<size[1];d1++){
	  for(int d2=0;d2<size[2];d2++){
	    other_coord[0] = d1;
	    other_coord[1] = d2;
	    size_t base = tensorDimensionBase<3>(0, other_coord, size);
	    for(int d0=0;d0<size[0];d0++)      
	      assert( tens_v.data()[base + d0*stride0] == tens_v(d0,d1,d2) );
	  }
	}
	//iter_dim=1
	for(int d0=0;d0<size[0];d0++){
	  for(int d2=0;d2<size[2];d2++){
	    other_coord[0] = d0;
	    other_coord[1] = d2;
	    size_t base = tensorDimensionBase<3>(1, other_coord, size);
	    for(int d1=0;d1<size[1];d1++)      
	      assert( tens_v.data()[base + d1*stride1] == tens_v(d0,d1,d2) );
	  }
	}
	//iter_dim=2
	for(int d0=0;d0<size[0];d0++){
	  for(int d1=0;d1<size[1];d1++){
	    other_coord[0] = d0;
	    other_coord[1] = d1;
	    size_t base = tensorDimensionBase<3>(2, other_coord, size);
	    for(int d2=0;d2<size[2];d2++)      
	      assert( tens_v.data()[base + d2*stride2] == tens_v(d0,d1,d2) );
	  }
	}
      });
  }


  {
    int size[4] = {2,3,4,5};
    Tensor<FloatType,4> tens(size);
    random(tens,rng);
    
    size_t stride0 = tensorDimensionStride<4>(0,size);
    size_t stride1 = tensorDimensionStride<4>(1,size);
    size_t stride2 = tensorDimensionStride<4>(2,size);
    size_t stride3 = tensorDimensionStride<4>(3,size);
    
    doHost(tens, {
	//iter_dim=0
	for(int d1=0;d1<size[1];d1++){
	  for(int d2=0;d2<size[2];d2++){
	    for(int b=0; b<size[3]; b++){
	      size_t o = d2 + size[2]*d1;
	      size_t base = batchTensorDimensionBaseLin<4>(0, b, o, size);

	      for(int d0=0;d0<size[0];d0++)      
		assert( tens_v.data()[base + d0*stride0] == tens_v(d0,d1,d2,b) );
	    }
	  }
	}

	//iter_dim=1
	for(int d0=0;d0<size[0];d0++){
	  for(int d2=0;d2<size[2];d2++){
	    for(int b=0; b<size[3]; b++){
	      size_t o = d2 + size[2]*d0;
	      size_t base = batchTensorDimensionBaseLin<4>(1, b, o, size);

	      for(int d1=0;d1<size[1];d1++)      
		assert( tens_v.data()[base + d1*stride1] == tens_v(d0,d1,d2,b) );
	    }
	  }
	}

	//iter_dim=2
	for(int d0=0;d0<size[0];d0++){
	  for(int d1=0;d1<size[1];d1++){
	    for(int b=0; b<size[3]; b++){
	      size_t o = d1 + size[1]*d0;
	      size_t base = batchTensorDimensionBaseLin<4>(2, b, o, size);

	      for(int d2=0;d2<size[2];d2++)      
		assert( tens_v.data()[base + d2*stride2] == tens_v(d0,d1,d2,b) );
	    }
	  }
	}
	
      });
  }

      
  std::cout << "testDimensionIteration passed" << std::endl;
}

	
/**
 * @brief Tests the functionality of tensor concatenation and splitting along different dimensions.
 *
 * This function tests the correctness of batchTensorConcatenate and batchTensorSplit functions
 * by comparing the results with expected values. It checks the concatenation and splitting
 * operations along three different dimensions (0, 1, and 2).
 * This comment was generated by meta-llama/Llama-3.3-70B-Instruct:None at temperature 0.2.
*/ 
void testConcatenateSplit(){
  typedef double FloatType;
  std::mt19937 rng(1234);
  
  { //contract dim 2
    int size1[4] = {2,3,4,5};
    int size2[4] = {2,3,3,5};
    int size3[4] = {2,3,6,5};

    std::vector<Tensor<FloatType,4>* > tens({ new Tensor<FloatType,4>(size1), new Tensor<FloatType,4>(size2), new Tensor<FloatType,4>(size3) });
    for(int i=0;i<3;i++)
      random(*tens[i],rng);

    Tensor<FloatType,4> got = batchTensorConcatenate(tens.data(), 3,  2);
    
    int osize[4] = {2,3,4+3+6,5};
    Tensor<FloatType,4> expect(osize, 0.);
    int off = 0;
    for(int t=0;t<3;t++){
      autoView(out_v,expect,HostReadWrite);
      autoView(in_v, (*tens[t]), HostRead);
      int csz = tens[t]->size(2);
      
      for(int i=0;i<2;i++)
	for(int j=0;j<3;j++)
	  for(int b=0;b<5;b++)
	    for(int k=0;k<csz;k++)
	      out_v(i,j,off + k,b) = in_v(i,j,k,b);
      off += csz;
    }

    assert(equal(got,expect,true));

    std::vector<Tensor<FloatType,4>* > split_tens({ new Tensor<FloatType,4>(size1), new Tensor<FloatType,4>(size2), new Tensor<FloatType,4>(size3) });
    
    batchTensorSplit(split_tens.data(), 3, got, 2);
    
    for(int t=0;t<3;t++){
      assert( equal(*split_tens[t], *tens[t], true) );
      
      delete tens[t];
      delete split_tens[t];
    }
  }

  { //contract dim 1
    int size1[4] = {2,4,3,5};
    int size2[4] = {2,3,3,5};
    int size3[4] = {2,6,3,5};

    std::vector<Tensor<FloatType,4>* > tens({ new Tensor<FloatType,4>(size1), new Tensor<FloatType,4>(size2), new Tensor<FloatType,4>(size3) });
    for(int i=0;i<3;i++)
      random(*tens[i],rng);

    Tensor<FloatType,4> got = batchTensorConcatenate<4,FloatType>(tens.data(), 3,  1);
    
    int osize[4] = {2,4+3+6,3,5};
    Tensor<FloatType,4> expect(osize, 0.);
    int off = 0;
    for(int t=0;t<3;t++){
      autoView(out_v,expect,HostReadWrite);
      autoView(in_v, (*tens[t]), HostRead);
      int csz = tens[t]->size(1);
      
      for(int i=0;i<2;i++)	  
	for(int k=0;k<3;k++)
	  for(int b=0;b<5;b++)
	    for(int j=0;j<csz;j++)
	      out_v(i,off + j,k,b) = in_v(i,j,k,b);
      off += csz;
    }

    assert(equal(got,expect,true));

    std::vector<Tensor<FloatType,4>* > split_tens({ new Tensor<FloatType,4>(size1), new Tensor<FloatType,4>(size2), new Tensor<FloatType,4>(size3) });
    
    batchTensorSplit(split_tens.data(), 3, got, 1);
    
    for(int t=0;t<3;t++){
      assert( equal(*split_tens[t], *tens[t], true) );
      
      delete tens[t];
      delete split_tens[t];
    }
  }

  { //contract dim 0
    int size1[4] = {4,2,3,5};
    int size2[4] = {3,2,3,5};
    int size3[4] = {6,2,3,5};

    std::vector<Tensor<FloatType,4>* > tens({ new Tensor<FloatType,4>(size1), new Tensor<FloatType,4>(size2), new Tensor<FloatType,4>(size3) });
    for(int i=0;i<3;i++)
      random(*tens[i],rng);

    Tensor<FloatType,4> got = batchTensorConcatenate<4,FloatType>(tens.data(), 3,  0);
    
    int osize[4] = {4+3+6,2,3,5};
    Tensor<FloatType,4> expect(osize, 0.);
    int off = 0;
    for(int t=0;t<3;t++){
      autoView(out_v,expect,HostReadWrite);
      autoView(in_v, (*tens[t]), HostRead);
      int csz = tens[t]->size(0);
      
      for(int j=0;j<2;j++)	  
	for(int k=0;k<3;k++)
	  for(int b=0;b<5;b++)
	    for(int i=0;i<csz;i++)
	      out_v(off + i,j,k,b) = in_v(i,j,k,b);
      off += csz;
    }

    assert(equal(got,expect,true));

    std::vector<Tensor<FloatType,4>* > split_tens({ new Tensor<FloatType,4>(size1), new Tensor<FloatType,4>(size2), new Tensor<FloatType,4>(size3) });
    
    batchTensorSplit(split_tens.data(), 3, got, 0);
    
    for(int t=0;t<3;t++){
      assert( equal(*split_tens[t], *tens[t], true) );
      
      delete tens[t];
      delete split_tens[t];
    }
    
  }
  std::cout << "testConcatenate passed" << std::endl;
}

  
/**
 * @brief Program entry point
 * @param argc Number of command line arguments
 * @param argv Array of command line argument strings
 * @return Exit status of the program
 * This comment was generated by meta-llama/Llama-3.3-70B-Instruct:None at temperature 0.2.
*/ 
int main(int argc, char** argv){
  initialize(argc,argv);
  
  testTensor();
  testDimensionIteration();
  testConcatenateSplit();
  return 0;
}
