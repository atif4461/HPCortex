#pragma once
#include <Tensors.hpp>

/**
 * @brief Rectified Linear Unit activation function implementation
 * 
 * Applies the ReLU operation to input matrices or tensors, optionally computing derivatives
 * This comment was generated by meta-llama/Llama-3.3-70B-Instruct:None at temperature 0.2.
*/ 
template<typename FloatType>
class ReLU{
public: 
  void operator()(Matrix<FloatType> &x, Matrix<FloatType> *deriv = nullptr) const;
  template<int Dim>
  void operator()(Tensor<FloatType,Dim> &x, Tensor<FloatType,Dim> *deriv = nullptr) const;
};

/**
 * @brief Linear activation function with f(x) = x.
 * 
 * This class represents a linear activation function where the output is equal to the input.
 * It provides overloaded operators for computing the activation and its derivative for matrices and tensors.
 * This comment was generated by meta-llama/Llama-3.3-70B-Instruct:None at temperature 0.2.
*/ 
template<typename FloatType>
class noActivation{
public:
  //f(x) = x
  inline void operator()(Matrix<FloatType> &x, Matrix<FloatType> *deriv = nullptr) const{
    if(deriv) *deriv = Matrix<FloatType>(x.size(0),x.size(1),1.0);
  }
  template<int Dim>
  inline void operator()(Tensor<FloatType,Dim> &x, Tensor<FloatType,Dim> *deriv = nullptr) const{
    if(deriv) *deriv = Tensor<FloatType,Dim>(x.sizeArray(),1.0);
  }
  
};

#include "implementation/ActivationFuncs.tcc"

// #ifndef ACTIVATIONFUNC_EXTERN_TEMPLATE_INST
// #define SS extern
// #else
// #define SS
// #endif
// SS template class ReLU<float>;
// SS template class ReLU<double>;
// SS template class noActivation<float>;
// SS template class noActivation<double>;
// #undef SS

